"factor()函数可以把变量变为因子类型，默认是没有等级之分的
（可以理解为无序分类变量nominal）！
当然也可以通过添加参数ordered=T变成有序因子（等级资料，有序分类ordinal）"



# 1.二项logistic回归------------------------------------------------------------
"二分类变量时，可以使用二项逻辑回归（binomial logistic regression）"
library(haven)
df16_2 <- read_sav("C:/Users/Administrator/Desktop/R脚本(SWY精心编辑版)/Medical Statistics/datasets/例16-02.sav")
View(df16_2)
# 变成因子型
df16_2[,c(2:10)] <- lapply(df16_2[,c(2:10)], factor)
str(df16_2)
f <- glm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8, data = df16_2, family = binomial())
summary(f)
# 1.1分类变量结果命名解释-------------------------------------------------------
# x12 x13 x14分别代表x1的第2 3 4 个参考水平和第一进行对比(类别大于2个以上)
# x21 x31 x41分别代表x2 x3 x4的第二个参考水平和各自的第一进行对比(类别只有2个时间)

# 1.2优化结果显示---------------------------------------------------------------
##### 1.2.1因子化变量的同时给变量上标签-----------------------------------------
df16_2$x1 <- factor(df16_2$x1, levels = c(1,2,3,4), labels = c("低级", "中级", "高级", "牛逼"))
df16_2$x2 <- factor(df16_2$x2, levels = c(0,1), labels = c("male", "female"))
df16_2$x3 <- factor(df16_2$x3, levels = c(0,1), labels = c("group1", "group2"))
df16_2$x4 <- factor(df16_2$x4, levels = c(0,1), labels = c("block1", "block2"))
df16_2$x5 <- factor(df16_2$x5, levels = c(0,1), labels = c("a1", "a2"))
df16_2$x6 <- factor(df16_2$x6, levels = c(0,1), labels = c("b1", "b2"))
df16_2$x7 <- factor(df16_2$x7, levels = c(1,2,3), labels = c("c1", "c2", "c3"))
df16_2$x8 <- factor(df16_2$x8, levels = c(0,1), labels = c("d1", "d2"))

f <- glm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8, data = df16_2, family = binomial())
summary(f)
broom::tidy(f)
# 这下结果就清晰了
"
Coefficients:
            Estimate Std. Error z value Pr(>|z|)   
(Intercept) -5.46026    2.07370  -2.633  0.00846 **
x1中级       0.85285    1.54399   0.552  0.58070   
x1高级       0.47754    1.59320   0.300  0.76438   
x1牛逼       3.44227    2.10985   1.632  0.10278   
x2female     1.14905    0.93176   1.233  0.21750   
x3group2     1.66039    1.16857   1.421  0.15535   
x4block2     0.85994    1.32437   0.649  0.51613   
x5a2         0.73600    0.97088   0.758  0.44840   
x6b2         3.92067    1.57004   2.497  0.01252 * 
x7c2        -0.03467    1.13363  -0.031  0.97560   
x7c3        -0.38230    1.61710  -0.236  0.81311   
x8d2         2.46322    1.10484   2.229  0.02578 * 
"
##### 1.2.2β值------------------------------------------------------------------
coefficients(f)

##### 1.2.3β值------------------------------------------------------------------
coef(f)

##### 1.2.4β值的95%可信区间-----------------------------------------------------
confint(f)

##### 1.2.5OR值-----------------------------------------------------------------
exp(coef(f))

##### 1.2.6# OR值的95%的可信区间------------------------------------------------
exp(confint(f))

##### 1.2.7Wald值---------------------------------------------------------------
# 等于β除以它的标准误（这里是Std. Error）
summary(f)$coefficients[,3]^2

##### 1.2.8P值------------------------------------------------------------------
summary(f)$coefficients[,4]

##### 1.2.9预测概率-------------------------------------------------------------
fitted(f)
predict(f,type = "response")
###### 1.2.9.1预测概率的说明----------------------------------------------------

# logistic回归来说，如果不使用type函数，
# 默认是type = "link"，返回的是logit(P)的值
# 默认返回logit(P)的值
predict(f)
# 返回概率
predict(f, type = "response")
# type = "response" 直接返回预测概率 （即 P(Y=1)），
# 因为二分类问题只需要一个概率值（另一个可通过 1−P 得到）
##### 1.2.10偏差----------------------------------------------------------------
deviance(f)

##### 1.2.11残差自由度----------------------------------------------------------
df.residual(f)


##### 1.3模型整体的假设检验和选择变量-------------------------------------------
# 先构建一个只有截距的模型
f0 <- glm(y ~ 1, data = df16_2, family = binomial())

anova(f0,f,test="Chisq")
# 向前
f1 <- step(f, direction = "forward")
summary(f1)
# 向后
f2 <- step(f, direction = "backward")
summary(f2)
# 步进法
f3 <- step(f, direction = "both")
summary(f3)
# 全子集回归
# 不行，目前最优自己只用于线性回归



